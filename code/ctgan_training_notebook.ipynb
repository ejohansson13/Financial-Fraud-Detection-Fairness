{"cells":[{"cell_type":"code","execution_count":null,"id":"d2Ex5E9peNw-","metadata":{"id":"d2Ex5E9peNw-"},"outputs":[],"source":["# coding=utf-8\n","#\n","# The copyright of this file belongs to Feedzai. The file cannot be\n","# reproduced in whole or in part, stored in a retrieval system,\n","# transmitted in any form, or by any means electronic, mechanical,\n","# photocopying, or otherwise, without the prior permission of the owner.\n","#\n","# (c) 2022 Feedzai, Strictly Confidential"]},{"cell_type":"code","execution_count":null,"id":"7Tw4isr6e40l","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":273,"status":"ok","timestamp":1721166734005,"user":{"displayName":"Erik Johansson","userId":"01074076572453530700"},"user_tz":420},"id":"7Tw4isr6e40l","outputId":"82e6d0db-d86a-4e3c-8619-4c24d20d0e87"},"outputs":[{"output_type":"stream","name":"stdout","text":["Python 3.10.12\n"]}],"source":["!python3 --version\n","# For python3.7 or 3.8, only requirements.txt requires installation"]},{"cell_type":"code","execution_count":null,"id":"4PsTljt8HbiU","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6563,"status":"ok","timestamp":1721166741325,"user":{"displayName":"Erik Johansson","userId":"01074076572453530700"},"user_tz":420},"id":"4PsTljt8HbiU","outputId":"4e9cdbe9-7256-4888-e543-d9beda38ece8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: aequitas in /usr/local/lib/python3.10/dist-packages (1.0.0)\n","Requirement already satisfied: matplotlib>=3.0.3 in /usr/local/lib/python3.10/dist-packages (from aequitas) (3.7.1)\n","Requirement already satisfied: pandas>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from aequitas) (2.0.3)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from aequitas) (6.0.1)\n","Requirement already satisfied: seaborn>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from aequitas) (0.13.1)\n","Requirement already satisfied: altair>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from aequitas) (4.2.2)\n","Requirement already satisfied: millify==0.1.1 in /usr/local/lib/python3.10/dist-packages (from aequitas) (0.1.1)\n","Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.10/dist-packages (from aequitas) (1.11.4)\n","Requirement already satisfied: optuna>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from aequitas) (3.6.1)\n","Requirement already satisfied: aif360>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from aequitas) (0.6.1)\n","Requirement already satisfied: fairgbm==0.9.14 in /usr/local/lib/python3.10/dist-packages (from aequitas) (0.9.14)\n","Requirement already satisfied: fairlearn>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from aequitas) (0.9.0)\n","Requirement already satisfied: hydra-core>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from aequitas) (1.3.2)\n","Requirement already satisfied: validators>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from aequitas) (0.33.0)\n","Requirement already satisfied: hyperparameter-tuning>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from aequitas) (0.3.1)\n","Requirement already satisfied: numpy==1.23.5 in /usr/local/lib/python3.10/dist-packages (from aequitas) (1.23.5)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from fairgbm==0.9.14->aequitas) (0.43.0)\n","Requirement already satisfied: scikit-learn!=0.22.0 in /usr/local/lib/python3.10/dist-packages (from fairgbm==0.9.14->aequitas) (1.2.2)\n","Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair>=4.1.0->aequitas) (0.4)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair>=4.1.0->aequitas) (3.1.4)\n","Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair>=4.1.0->aequitas) (4.19.2)\n","Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair>=4.1.0->aequitas) (0.12.1)\n","Requirement already satisfied: omegaconf<2.4,>=2.2 in /usr/local/lib/python3.10/dist-packages (from hydra-core>=1.3.0->aequitas) (2.3.0)\n","Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.10/dist-packages (from hydra-core>=1.3.0->aequitas) (4.9.3)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from hydra-core>=1.3.0->aequitas) (24.1)\n","Requirement already satisfied: schema in /usr/local/lib/python3.10/dist-packages (from hyperparameter-tuning>=0.3.1->aequitas) (0.7.7)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.3->aequitas) (1.2.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.3->aequitas) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.3->aequitas) (4.53.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.3->aequitas) (1.4.5)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.3->aequitas) (9.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.3->aequitas) (3.1.2)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.3->aequitas) (2.8.2)\n","Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from optuna>=3.0.0->aequitas) (1.13.2)\n","Requirement already satisfied: colorlog in /usr/local/lib/python3.10/dist-packages (from optuna>=3.0.0->aequitas) (6.8.2)\n","Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna>=3.0.0->aequitas) (2.0.31)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna>=3.0.0->aequitas) (4.66.4)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.1->aequitas) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.1->aequitas) (2024.1)\n","Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna>=3.0.0->aequitas) (1.3.5)\n","Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna>=3.0.0->aequitas) (4.12.2)\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair>=4.1.0->aequitas) (23.2.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair>=4.1.0->aequitas) (2023.12.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair>=4.1.0->aequitas) (0.35.1)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair>=4.1.0->aequitas) (0.19.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.0.3->aequitas) (1.16.0)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn!=0.22.0->fairgbm==0.9.14->aequitas) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn!=0.22.0->fairgbm==0.9.14->aequitas) (3.5.0)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna>=3.0.0->aequitas) (3.0.3)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair>=4.1.0->aequitas) (2.1.5)\n"]}],"source":["%pip install aequitas # library for metrics"]},{"cell_type":"code","execution_count":null,"id":"3OQMaEySe6dE","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":89280,"status":"ok","timestamp":1721166831321,"user":{"displayName":"Erik Johansson","userId":"01074076572453530700"},"user_tz":420},"id":"3OQMaEySe6dE","outputId":"f31ade70-adb6-4dc3-c0d7-fedd2c51c0b2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting sdv\n","  Downloading sdv-1.15.0-py3-none-any.whl (146 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m146.4/146.4 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting boto3>=1.28 (from sdv)\n","  Downloading boto3-1.34.144-py3-none-any.whl (139 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.2/139.2 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting botocore>=1.31 (from sdv)\n","  Downloading botocore-1.34.144-py3-none-any.whl (12.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m39.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: cloudpickle>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from sdv) (2.2.1)\n","Requirement already satisfied: graphviz>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from sdv) (0.20.3)\n","Requirement already satisfied: tqdm>=4.29 in /usr/local/lib/python3.10/dist-packages (from sdv) (4.66.4)\n","Collecting copulas>=0.11.0 (from sdv)\n","  Downloading copulas-0.11.0-py3-none-any.whl (51 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.9/51.9 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting ctgan>=0.10.0 (from sdv)\n","  Downloading ctgan-0.10.1-py3-none-any.whl (24 kB)\n","Collecting deepecho>=0.6.0 (from sdv)\n","  Downloading deepecho-0.6.0-py3-none-any.whl (27 kB)\n","Collecting rdt>=1.12.0 (from sdv)\n","  Downloading rdt-1.12.2-py3-none-any.whl (65 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.2/65.2 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting sdmetrics>=0.14.0 (from sdv)\n","  Downloading sdmetrics-0.15.0-py3-none-any.whl (170 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.5/170.5 kB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: platformdirs>=4.0 in /usr/local/lib/python3.10/dist-packages (from sdv) (4.2.2)\n","Requirement already satisfied: pyyaml>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from sdv) (6.0.1)\n","Requirement already satisfied: pandas>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from sdv) (2.0.3)\n","Requirement already satisfied: numpy<2.0.0,>=1.23.3 in /usr/local/lib/python3.10/dist-packages (from sdv) (1.23.5)\n","Collecting jmespath<2.0.0,>=0.7.1 (from boto3>=1.28->sdv)\n","  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n","Collecting s3transfer<0.11.0,>=0.10.0 (from boto3>=1.28->sdv)\n","  Downloading s3transfer-0.10.2-py3-none-any.whl (82 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.7/82.7 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore>=1.31->sdv) (2.8.2)\n","Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore>=1.31->sdv) (2.0.7)\n","Requirement already satisfied: plotly>=5.10.0 in /usr/local/lib/python3.10/dist-packages (from copulas>=0.11.0->sdv) (5.15.0)\n","Requirement already satisfied: scipy>=1.9.2 in /usr/local/lib/python3.10/dist-packages (from copulas>=0.11.0->sdv) (1.11.4)\n","Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from ctgan>=0.10.0->sdv) (2.3.0+cu121)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.0->sdv) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.0->sdv) (2024.1)\n","Collecting Faker>=17 (from rdt>=1.12.0->sdv)\n","  Downloading Faker-26.0.0-py3-none-any.whl (1.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m72.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from rdt>=1.12.0->sdv) (1.2.2)\n","Collecting plotly>=5.10.0 (from copulas>=0.11.0->sdv)\n","  Downloading plotly-5.22.0-py3-none-any.whl (16.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m77.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly>=5.10.0->copulas>=0.11.0->sdv) (8.5.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from plotly>=5.10.0->copulas>=0.11.0->sdv) (24.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore>=1.31->sdv) (1.16.0)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.1.0->rdt>=1.12.0->sdv) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.1.0->rdt>=1.12.0->sdv) (3.5.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->ctgan>=0.10.0->sdv) (3.15.4)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->ctgan>=0.10.0->sdv) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->ctgan>=0.10.0->sdv) (1.13.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->ctgan>=0.10.0->sdv) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->ctgan>=0.10.0->sdv) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->ctgan>=0.10.0->sdv) (2023.6.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.11.0->ctgan>=0.10.0->sdv)\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.11.0->ctgan>=0.10.0->sdv)\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.11.0->ctgan>=0.10.0->sdv)\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.11.0->ctgan>=0.10.0->sdv)\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.11.0->ctgan>=0.10.0->sdv)\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.11.0->ctgan>=0.10.0->sdv)\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.11.0->ctgan>=0.10.0->sdv)\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.11.0->ctgan>=0.10.0->sdv)\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.11.0->ctgan>=0.10.0->sdv)\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.11.0->ctgan>=0.10.0->sdv)\n","  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.11.0->ctgan>=0.10.0->sdv)\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->ctgan>=0.10.0->sdv) (2.3.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->ctgan>=0.10.0->sdv)\n","  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m70.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->ctgan>=0.10.0->sdv) (2.1.5)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->ctgan>=0.10.0->sdv) (1.3.0)\n","Installing collected packages: plotly, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, jmespath, nvidia-cusparse-cu12, nvidia-cudnn-cu12, Faker, botocore, s3transfer, rdt, nvidia-cusolver-cu12, copulas, sdmetrics, boto3, deepecho, ctgan, sdv\n","  Attempting uninstall: plotly\n","    Found existing installation: plotly 5.15.0\n","    Uninstalling plotly-5.15.0:\n","      Successfully uninstalled plotly-5.15.0\n","Successfully installed Faker-26.0.0 boto3-1.34.144 botocore-1.34.144 copulas-0.11.0 ctgan-0.10.1 deepecho-0.6.0 jmespath-1.0.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 plotly-5.22.0 rdt-1.12.2 s3transfer-0.10.2 sdmetrics-0.15.0 sdv-1.15.0\n"]}],"source":["#%pip install ctgan\n","%pip install sdv\n","# sdv is newer library compatible with python 3.10\n","# if using python 3.7 or 3.8, ctgan library is compatible and likely easier to use"]},{"cell_type":"code","execution_count":null,"id":"T51ymqRofRvo","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5649,"status":"ok","timestamp":1721166836967,"user":{"displayName":"Erik Johansson","userId":"01074076572453530700"},"user_tz":420},"id":"T51ymqRofRvo","outputId":"8a3df668-1097-4094-bedf-bc828dfe4803"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: optuna in /usr/local/lib/python3.10/dist-packages (3.6.1)\n","Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (1.13.2)\n","Requirement already satisfied: colorlog in /usr/local/lib/python3.10/dist-packages (from optuna) (6.8.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (24.1)\n","Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.31)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.4)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.1)\n","Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (1.3.5)\n","Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (3.0.3)\n","Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.5)\n"]}],"source":["%pip install optuna # hyperpameter search space optimizer"]},{"cell_type":"code","execution_count":null,"id":"EjiiQ3IJfX06","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5559,"status":"ok","timestamp":1721166842522,"user":{"displayName":"Erik Johansson","userId":"01074076572453530700"},"user_tz":420},"id":"EjiiQ3IJfX06","outputId":"e6818eae-6774-4bf6-d620-aed31216760f"},"outputs":[{"output_type":"stream","name":"stdout","text":["1.15.0\n"]}],"source":["import sdv\n","print(sdv.__version__) # double check sdv version"]},{"cell_type":"code","execution_count":null,"id":"1xirWec-eNxB","metadata":{"id":"1xirWec-eNxB"},"outputs":[],"source":["import copy\n","from sdv.single_table import CTGANSynthesizer     # import synthesization model\n","from sdv.metadata import SingleTableMetadata      # metadata reader for synthesization model\n","import logging          # redirect output messages\n","import numpy as np      # random number generation\n","import os               # file management\n","import pandas as pd     # read/write data\n","import pathlib          # file navigation\n","import yaml             # reading configuration files\n","\n","from contextlib import redirect_stdout, redirect_stderr\n","from dataclasses import dataclass, field\n","from numpy import random\n","from sklearn import preprocessing\n","from sklearn import utils\n","from typing import Dict, Union"]},{"cell_type":"code","execution_count":null,"id":"Yd4tYBWoHeAO","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14125,"status":"ok","timestamp":1721166859066,"user":{"displayName":"Erik Johansson","userId":"01074076572453530700"},"user_tz":420},"id":"Yd4tYBWoHeAO","outputId":"ef757516-493d-4a93-c1a7-bdd7d38774f0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive/')"]},{"cell_type":"code","execution_count":null,"id":"fR209FcVflsM","metadata":{"id":"fR209FcVflsM"},"outputs":[],"source":["!cp /content/drive/MyDrive/Colab\\ Notebooks/ECE697/Project/random_search.py ."]},{"cell_type":"code","execution_count":null,"id":"K4-Efl6NHhL9","metadata":{"id":"K4-Efl6NHhL9"},"outputs":[],"source":["from random_search import RandomValueTrial, suggest_callable_hyperparams, suggest_hyperparams"]},{"cell_type":"code","execution_count":null,"id":"134e04e8","metadata":{"id":"134e04e8"},"outputs":[],"source":["# Declaration of categorical featuers\n","CATEGORICAL_FEATURES = [\n","    'source',\n","    'payment_type',\n","    'device_os',\n","    'housing_status',\n","    'employment_status',\n","    'month'\n","]\n","\n","# Declaration of boolean features\n","BOOLEAN_FEATURES = [\n","    'email_is_free',\n","    'fraud_bool',\n","    'foreign_request',\n","    'keep_alive_session',\n","    'phone_home_valid',\n","    'phone_mobile_valid',\n","    'has_other_cards',\n","]\n","\n","# Number of attempts for each synthesization model\n","N_RUNS = 1\n","\n","# Desired False Positive Ratio for synthesizing data\n","TARGET_FPR = 0.05"]},{"cell_type":"code","execution_count":null,"id":"b6a774be","metadata":{"id":"b6a774be"},"outputs":[],"source":["args = {\n","    \"run_dir\": \"/content/drive/MyDrive/Colab Notebooks/ECE697/Project/CTGAN Data\", # storage of shuffled training data\n","    'config_path': \"/content/drive/MyDrive/Colab Notebooks/ECE697/Project/config-rs.yml\", # yaml configuration file\n","    'n_procs': 1, # number of processes for multiprocessing\n","    'devices': [\"cuda:0\"], # gpu devices\n","    'log_level': \"DEBUG\",  # logging configuration\n","    'seed': 42,            # random seed for reproducibility\n","    'dry_run': False,\n","    'dev_run': False,\n","    'n_trials': 4,         # total synthesization datasets created\n","}"]},{"cell_type":"code","execution_count":null,"id":"8e3dc347","metadata":{"id":"8e3dc347"},"outputs":[],"source":["@dataclass\n","class RunConfig:\n","    \"\"\"Dataclass with required information to train a model.\"\"\"\n","    model_id: int\n","\n","    train_df: pd.DataFrame = field(repr=False)\n","    val_df: pd.DataFrame = field(repr=False)\n","    discrete_columns: list\n","\n","    model_run_dir: str\n","\n","    config: Dict\n","\n","    seed: Union[int, None]"]},{"cell_type":"code","execution_count":null,"id":"562312d6","metadata":{"id":"562312d6"},"outputs":[],"source":["# Specifying logging detials for warning and error messages\n","def configure_logging(log_arg):\n","    received_level = getattr(logging, log_arg.upper(), None)\n","\n","    logging_level = received_level if received_level else logging.INFO\n","\n","    logging.basicConfig(\n","        format='[ %(levelname)s ] %(asctime)s (%(process)s-%(processName)s) %(message)s',\n","        datefmt='%Y-%m-%d %H:%M:%S',\n","        level=logging_level\n","    )\n","\n","    if not received_level:\n","        logging.warning('Unknown logging level %s: Setting logging to INFO', log_arg.upper())"]},{"cell_type":"code","execution_count":null,"id":"358d129f","metadata":{"id":"358d129f"},"outputs":[],"source":["# Creating directory for CTGANSynthesizer runs\n","# Exits with error if directory already exists\n","def create_run_dir(run_dir):\n","    if run_dir.exists():\n","        logging.error('Run Directory already exists: \\'%s\\'', run_dir)\n","        exit(1)\n","\n","    os.mkdir(run_dir)\n","\n","    logging.info('Run results stored at: \\'%s\\'', run_dir)"]},{"cell_type":"code","execution_count":null,"id":"bb9ba0bc","metadata":{"id":"bb9ba0bc"},"outputs":[],"source":["# Reading synthesizer model configurations from yaml files\n","def read_configurations(config_path):\n","    logging.info('Reading configurations from %s', config_path)\n","\n","    with open(config_path, 'r') as f:\n","        configs = yaml.safe_load(f)\n","\n","    return configs['data'], configs['sweep_params']"]},{"cell_type":"code","execution_count":null,"id":"9ac75369","metadata":{"id":"9ac75369"},"outputs":[],"source":["def load_data(data_config):\n","\n","    logging.info('Loading train dataset from \\'%s\\'', data_config['train'])\n","    logging.info('Loading validation dataset from \\'%s\\'', data_config['validation'])\n","\n","    train_df = pd.read_csv(data_config['train'])\n","    val_df = pd.read_csv(data_config['validation'])\n","    #train_df = pd.read_csv(data_config['train'], index_col=0)\n","    #val_df = pd.read_csv(data_config['validation'], index_col=0)\n","\n","    if 'keep' in data_config:\n","        train_df = train_df[data_config['keep']]\n","        val_df = val_df[data_config['keep']]\n","    elif 'remove' in data_config:\n","        train_df = train_df.drop(columns=data_config['remove'])\n","        val_df = val_df.drop(columns=data_config['remove'])\n","\n","    discrete_columns = [f for f in CATEGORICAL_FEATURES + BOOLEAN_FEATURES if f in train_df.columns]\n","\n","    logging.info('Train Dataset: %s Features, %s Rows', len(train_df.columns), len(train_df))\n","    logging.info('Validation Dataset: %s Features, %s Rows', len(val_df.columns), len(val_df))\n","    logging.debug('Train Features: %s', list(train_df.columns))\n","    logging.debug('Validation features: %s', list(val_df.columns))\n","    logging.debug('Discrete columns: %s', discrete_columns)\n","\n","    return train_df, val_df, discrete_columns"]},{"cell_type":"code","execution_count":null,"id":"9fbc778a","metadata":{"id":"9fbc778a"},"outputs":[],"source":["# Just path functions\n","\n","def pad_int(model_id, zfill=3):\n","    return str(model_id).zfill(zfill)\n","\n","def model_run_dir(run_dir, model_id):\n","    return run_dir / pad_int(model_id)\n","\n","def config_path(model_run_dir, model_id):\n","    return model_run_dir / f'config-{pad_int(model_id)}.yml'\n","\n","\n","def model_path(model_run_dir, model_id):\n","    return model_run_dir / f'model-{pad_int(model_id)}.pkl'\n","\n","\n","def train_dataset_path(model_run_dir, model_id):\n","    return model_run_dir / f'train-dataset-{pad_int(model_id)}.csv'\n","\n","\n","def synthetic_dataset_path(model_run_dir, model_id):\n","    return model_run_dir / f'synthetic-dataset-{pad_int(model_id)}.csv'\n","\n","\n","def model_evaluation_path(model_run_dir, model_id):\n","    return model_run_dir / f'evaluation-{pad_int(model_id)}.csv'\n","\n","\n","def stdout_path(model_run_dir, model_id):\n","    return model_run_dir / f'stdout-{pad_int(model_id)}.log'\n","\n","\n","def stderr_path(model_run_dir, model_id):\n","    return model_run_dir/ f'stderr-{pad_int(model_id)}.log'"]},{"cell_type":"code","execution_count":null,"id":"19df14aa","metadata":{"id":"19df14aa"},"outputs":[],"source":["def build_run_configs(\n","        run_dir: str,\n","        datasets_config: dict,\n","        data_sweep_params: dict,\n","        model_sweep_params: dict,\n","        devices: list,\n","        n_trials: int,\n","        seed: int,\n",") -> list:\n","    train_df, val_df, discrete_columns = load_data(datasets_config)\n","\n","    run_configs = []\n","\n","    random.seed(seed)\n","    seeds = random.randint(n_trials*1000, size=n_trials)\n","    for i, seed  in enumerate(seeds, start=1):\n","        # Method to random sample configurations\n","        configs_data =  suggest_hyperparams(RandomValueTrial(seed=seed), data_sweep_params)\n","        configs_model = suggest_hyperparams(RandomValueTrial(seed=seed), model_sweep_params['kwargs'])\n","        configs_model['generator_dim'] = eval(configs_model['generator_dim'])\n","        configs_model['discriminator_dim'] = eval(configs_model['discriminator_dim'])\n","        configs_model['generator_decay'] = eval(configs_model['generator_decay'])\n","        configs_model['discriminator_decay'] = eval(configs_model['discriminator_decay'])\n","        configs_model['cuda'] = devices[i % len(devices)]\n","        config = {\"data\": configs_data, \"model\": configs_model}\n","        run_configs.append(\n","            RunConfig(\n","                model_id=i,\n","                train_df=train_df,\n","                val_df=val_df,\n","                discrete_columns=discrete_columns,\n","                model_run_dir=model_run_dir(run_dir, i),\n","                config=config,\n","                seed=seed,\n","            )\n","        )\n","\n","\n","    return run_configs"]},{"cell_type":"code","execution_count":null,"id":"3b26892c","metadata":{"id":"3b26892c"},"outputs":[],"source":["# account for fraud prevalence specified in configuration file\n","def subsample_with_prevalence(df, prevalence, seed):\n","    if prevalence:\n","        fraud = df[df['fraud_bool'] == 1]\n","        non_fraud = df[df['fraud_bool'] == 0]\n","\n","        fraud_proportion, non_fraud_proportion = prevalence # read prevalence proportions from yaml configuration file\n","        non_fraud_instances = (len(fraud) * non_fraud_proportion) // fraud_proportion\n","        # check preferred prevalence proportions are possible given base dataset\n","        if non_fraud_instances >= len(non_fraud):\n","            logging.warning(\n","                'Unable to subsample dataframe: Expected more than %s negative examples but got %s',\n","                non_fraud_instances,\n","                len(fraud)\n","            )\n","            non_fraud_sample = non_fraud\n","        else:\n","            non_fraud_sample = non_fraud.sample(n=non_fraud_instances, random_state=seed)\n","        return utils.shuffle(pd.concat((fraud, non_fraud_sample)), random_state=seed)\n","    else:\n","        return df"]},{"cell_type":"code","execution_count":null,"id":"2ea34395","metadata":{"id":"2ea34395"},"outputs":[],"source":["def apply_config_to_data(df, data_config, model_id, seed):\n","\n","    if 'prevalence' in data_config:\n","        df = subsample_with_prevalence(df, eval(data_config['prevalence']), seed)\n","\n","    if logging.root.isEnabledFor(logging.DEBUG):\n","        logging.debug(\n","            'Model %s: Dataset with %s Examples (%s fraud, %s non fraud)',\n","            pad_int(model_id),\n","            len(df),\n","            len(df[df['fraud_bool'] == 1]),\n","            len(df[df['fraud_bool'] == 0])\n","        )\n","\n","    return df"]},{"cell_type":"code","execution_count":null,"id":"dec6b4b7","metadata":{"id":"dec6b4b7"},"outputs":[],"source":["def preprocess_categorical(train_df, val_df, discrete_columns):\n","\n","    categorical_columns = np.intersect1d(discrete_columns, CATEGORICAL_FEATURES)\n","\n","    for column in categorical_columns:\n","        train_unique = train_df[column].unique()\n","        val_unique = val_df[column].unique()\n","        nans = np.setdiff1d(val_unique, train_unique)\n","        val_df.loc[val_df[column].isin(nans), [column]] = np.nan\n","\n","    train_dummy = pd.get_dummies(train_df, columns=categorical_columns, dummy_na=True)\n","    val_dummy = pd.get_dummies(val_df, columns=categorical_columns, dummy_na=True)\n","\n","    for unseen_column in np.setdiff1d(train_dummy.columns, val_dummy.columns):\n","        val_dummy[unseen_column] = 0\n","\n","    return train_dummy, val_dummy\n","\n","def split(train_df, val_df, target):\n","    train_x = train_df.drop(columns=[target])\n","    train_y = train_df[target]\n","    val_x = val_df.drop(columns=[target])\n","    val_y = val_df[target]\n","    return train_x, train_y, val_x, val_y\n","\n","def preprocess_and_split(train_df, val_df, discrete_columns, target):\n","    train_dummy_df, val_dummy_df = preprocess_categorical(train_df, val_df, discrete_columns)\n","    return split(train_dummy_df, val_dummy_df, target)"]},{"cell_type":"code","execution_count":null,"id":"fd336d1d","metadata":{"id":"fd336d1d"},"outputs":[],"source":["def class_index(model, class_value):\n","    return np.argwhere(model.classes_ == class_value)[0]\n","\n","\n","def prediction_probabilities(model, x):\n","    return model.predict_proba(x)[:, class_index(model, 1)]"]},{"cell_type":"code","execution_count":null,"id":"b1218992","metadata":{"id":"b1218992"},"outputs":[],"source":["# transforms categorical features to numbers in training and validation dataframes\n","def ordinal_encode(train_df, val_df, categorical_features):\n","    for f in categorical_features:\n","        enc = preprocessing.OrdinalEncoder()\n","        train_df[f] = enc.fit_transform(train_df[[f]])\n","        val_df[f] = enc.fit_transform(val_df[[f]])\n","    return train_df, val_df\n"]},{"cell_type":"code","execution_count":null,"id":"9f042403","metadata":{"id":"9f042403"},"outputs":[],"source":["# fairness metric calculations\n","def compile_results(\n","        real_fprs,\n","        real_tprs,\n","        real_thresholds,\n","        synthetic_train_fprs,\n","        synthetic_train_tprs,\n","        synthetic_train_thresholds,\n","        synthetic_val_fprs,\n","        synthetic_val_tprs,\n","        synthetic_val_thresholds,\n","        synthetic_both_fprs,\n","        synthetic_both_tprs,\n","        synthetic_both_thresholds):\n","\n","    records = []\n","    for i, results in enumerate(zip(real_fprs, real_tprs, real_thresholds), start=1):\n","        for fpr, tpr, threshold in zip(*results):\n","            records.append((i, fpr, tpr, threshold, 'real'))\n","\n","    for j, results in enumerate(zip(synthetic_train_fprs, synthetic_train_tprs, synthetic_train_thresholds), start=i+1):\n","        for fpr, tpr, threshold in zip(*results):\n","            records.append((j, fpr, tpr, threshold, 'synthetic-train'))\n","\n","    for k, results in enumerate(zip(synthetic_val_fprs, synthetic_val_tprs, synthetic_val_thresholds), start=j+1):\n","        for fpr, tpr, threshold in zip(*results):\n","            records.append((k, fpr, tpr, threshold, 'synthetic-val'))\n","\n","    for n, results in enumerate(zip(synthetic_both_fprs, synthetic_both_tprs, synthetic_both_thresholds), start=k+1):\n","        for fpr, tpr, threshold in zip(*results):\n","            records.append((n, fpr, tpr, threshold, 'synthetic-both'))\n","\n","    return pd.DataFrame.from_records(records, columns=['run_id', 'fpr', 'tpr', 'threshold', 'discrimination'])\n","\n","\n","def summarize_results(\n","        real_fprs,\n","        real_tprs,\n","        real_thresholds,\n","        synthetic_train_fprs,\n","        synthetic_train_tprs,\n","        synthetic_train_thresholds,\n","        synthetic_val_fprs,\n","        synthetic_val_tprs,\n","        synthetic_val_thresholds,\n","        synthetic_both_fprs,\n","        synthetic_both_tprs,\n","        synthetic_both_thresholds):\n","\n","    def compute_avg_tpr_and_threshold(fprs, tprs, thresholds):\n","        avg_tpr = 0\n","        avg_threshold = 0\n","\n","        for run_fprs, run_tprs, run_thresholds in zip(fprs, tprs, thresholds):\n","            target_fpr_index = np.argwhere(run_fprs <= TARGET_FPR).ravel()[-1]\n","            avg_tpr += run_tprs[target_fpr_index] / N_RUNS\n","            avg_threshold += run_thresholds[target_fpr_index] / N_RUNS\n","\n","        return avg_tpr, avg_threshold\n","\n","    avg_real_tpr, avg_real_threshold = \\\n","        compute_avg_tpr_and_threshold(real_fprs, real_tprs, real_thresholds)\n","\n","    avg_synthetic_train_tpr, avg_synthetic_train_threshold = \\\n","        compute_avg_tpr_and_threshold(synthetic_train_fprs, synthetic_train_tprs, synthetic_train_thresholds)\n","\n","    avg_synthetic_val_tpr, avg_synthetic_val_threshold = \\\n","        compute_avg_tpr_and_threshold(synthetic_val_fprs, synthetic_val_tprs, synthetic_val_thresholds)\n","\n","    avg_synthetic_both_tpr, avg_synthetic_both_threshold = \\\n","        compute_avg_tpr_and_threshold(synthetic_both_fprs, synthetic_both_tprs, synthetic_both_thresholds)\n","\n","    return (\n","        avg_real_tpr,\n","        avg_real_threshold,\n","        avg_synthetic_train_tpr,\n","        avg_synthetic_train_threshold,\n","        avg_synthetic_val_tpr,\n","        avg_synthetic_val_threshold,\n","        avg_synthetic_both_tpr,\n","        avg_synthetic_both_threshold\n","    )"]},{"cell_type":"code","execution_count":null,"id":"IPDADDRwrMch","metadata":{"id":"IPDADDRwrMch"},"outputs":[],"source":["def run_instance(run_config: RunConfig):\n","    #device = args['devices'][0]\n","\n","    model_id = run_config.model_id\n","\n","    train_df = run_config.train_df\n","    val_df = run_config.val_df\n","    #discrete_columns = run_config.discrete_columns\n","\n","    model_run_dir = pathlib.Path(run_config.model_run_dir)\n","\n","    config = run_config.config\n","    config_save_path = config_path(model_run_dir, model_id)\n","    model_save_path = model_path(model_run_dir, model_id)\n","    model_evaluation_save_path = model_evaluation_path(model_run_dir, model_id)\n","    train_data_save_path = train_dataset_path(model_run_dir, model_id)\n","    synthetic_data_save_path = synthetic_dataset_path(model_run_dir, model_id)\n","\n","    run_stdout_path = stdout_path(model_run_dir, model_id)\n","    run_stderr_path = stderr_path(model_run_dir, model_id)\n","\n","    seed = run_config.seed\n","\n","    logging.info('Model %s: Training started', pad_int(model_id))\n","    logging.debug('Model %s: Config %s', pad_int(model_id), config)\n","    logging.debug('Model %s: Saved config to \\'%s\\'', pad_int(model_id), config_save_path)\n","    logging.debug('Model %s: Stdout redirected to \\'%s\\'', pad_int(model_id), run_stdout_path)\n","    logging.debug('Model %s: Stderr redirected to \\'%s\\'', pad_int(model_id), run_stderr_path)\n","\n","    data_config = config['data']\n","    model_config = config['model']\n","\n","    df = pd.concat((train_df, val_df))\n","    df = utils.shuffle(df)\n","    df = apply_config_to_data(df, data_config, model_id, seed)\n","\n","    os.mkdir(model_run_dir)\n","\n","    df.to_csv(train_data_save_path)\n","    logging.debug('Model %s: Training data saved to %s', \"pad_int(model_id)\", train_data_save_path)\n","\n","    metadata_obj = SingleTableMetadata()\n","    metadata_obj.detect_from_dataframe(df)\n","\n","    with open(config_save_path, 'w') as fd:\n","        yaml.safe_dump(config, stream=fd, default_flow_style=False)\n","\n","    model = CTGANSynthesizer(metadata=metadata_obj, **model_config)\n","    #model.to(device)\n","\n","    with open(run_stdout_path, 'w') as out_fd, open(run_stderr_path, 'w') as err_fd:\n","        with redirect_stdout(out_fd), redirect_stderr(err_fd):\n","            model.fit(df)\n","\n","    model.save(model_save_path)\n","\n","    logging.info('Model %s: Saved model to \\'%s\\'', pad_int(model_id), model_save_path)\n","\n","    synthetic_df = model.sample(len(df))\n","    synthetic_df.to_csv(synthetic_data_save_path)\n","\n","    logging.info('Model %s: Saved synthetic dataset to \\'%s\\'', pad_int(model_id), synthetic_data_save_path)\n","\n","    return model_id, synthetic_df"]},{"cell_type":"code","source":["def run_experiment():\n","    run_dir = pathlib.Path(args['run_dir'])\n","\n","    config_path = args['config_path']\n","    n_procs = args['n_procs']\n","    devices = args['devices']\n","    dry_run = args['dry_run']\n","    seed = args['seed']\n","    n_trials = args['n_trials']\n","\n","    configure_logging(args['log_level'])\n","\n","    if seed:\n","        seed = int(seed)\n","        logging.info('Using seed value: %s', seed)\n","\n","    create_run_dir(run_dir)\n","\n","    datasets_config, sweep_params = read_configurations(config_path)\n","\n","    data_sweep_params = sweep_params['data']\n","    model_sweep_params = sweep_params['model']\n","\n","    run_configs = build_run_configs(\n","        run_dir,\n","        datasets_config,\n","        data_sweep_params,\n","        model_sweep_params,\n","        devices,\n","        n_trials,\n","        seed\n","    )\n","\n","    dfs = []\n","    for synthetic_df in map(run_instance, run_configs):\n","        if not dry_run:\n","            dfs.append(synthetic_df)\n","\n","    logging.info('Finished Successfully')\n","\n","\n","if __name__ == '__main__':\n","    run_experiment()"],"metadata":{"id":"HZ4bvShlG8Np"},"id":"HZ4bvShlG8Np","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"b42TzFPnnFok","metadata":{"id":"b42TzFPnnFok"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"L4","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.7"}},"nbformat":4,"nbformat_minor":5}